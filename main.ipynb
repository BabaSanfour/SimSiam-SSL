{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-supervised learning \n",
    "Experimenting on Simsiam, a simple and effective Self-supervised learning (SSL) method.\n",
    "\n",
    "The Simsiam architecture as shown in this figure (from https://arxiv.org/pdf/2011.10566.pdf). \n",
    "\n",
    "\n",
    "![1-Figure1-1.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requirements\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from model  import SimSiam\n",
    "\n",
    "from utils import TwoCropsTransform, load_checkpoints, load_pretrained_checkpoints\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# general\n",
    "seed = 2022\n",
    "num_workers = 2\n",
    "save_path = './'\n",
    "resume = None # None or a path to a pretrained model (e.g. *.pth.tar')\n",
    "start_epoch = 0\n",
    "epochs = 200 # Number of epoches (for this question 200 is enough, however for 1000 epoches, you will get closer results to the original paper)\n",
    "\n",
    "# data\n",
    "dir ='./data'\n",
    "batch_size = 1024\n",
    "\n",
    "# Siamese backbone model\n",
    "arch = \"resnet18\"\n",
    "fix_pred_lr = True # fix the learning rate of the predictor network\n",
    "\n",
    "#Simsiam params\n",
    "dim=2048\n",
    "pred_dim=512\n",
    "\n",
    "# ablation experiments\n",
    "stop_gradient=False # (True or False)\n",
    "MLP_mode=None # None|'no_pred_mlp'\n",
    "\n",
    "# optimizer\n",
    "lr = 0.03\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "\n",
    "# knn params\n",
    "knn_k = 200 #k in kNN monitor\n",
    "knn_t = 0.1 #softmax temperature in kNN monitor; could be different with moco-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet18'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimSiam(\n",
       "  (encoder): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (7): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (predictor): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=False)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simsiam Model\n",
    "print(\"=> creating model '{}'\".format(arch))\n",
    "model = SimSiam(models.__dict__[arch], dim, pred_dim, stop_gradient=True, MLP_mode=None)\n",
    "# print(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and set learning rates\n",
    "init_lr = lr * batch_size / 256\n",
    "if fix_pred_lr:\n",
    "    optim_params = [{'params': model.encoder.parameters(), 'fix_lr': False},\n",
    "                    {'params': model.predictor.parameters(), 'fix_lr': True}]\n",
    "else:\n",
    "    optim_params = model.parameters()\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(optim_params, init_lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can resume from a previous checkpoint\n",
    "if resume:\n",
    "    model, optimizer, start_epoch = load_checkpoints(os.path.join(resume),model,optimizer,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe046f7d7eb4d97a6d76e51daec9f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataset and dataloader for Siamese network\n",
    "# define train and test augmentations for pretraining step \n",
    "train_transform = [\n",
    "    transforms.RandomResizedCrop(32, scale=(0.08, 1.)), \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])]\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "# datasets and loaders\n",
    "train_data = datasets.CIFAR10(root=dir, train=True, transform=TwoCropsTransform(transforms.Compose(train_transform)), download=True)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "memory_data = datasets.CIFAR10(root=dir, train=True, transform=test_transform, download=True)\n",
    "memory_loader = DataLoader(memory_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "test_data = datasets.CIFAR10(root=dir, train=False, transform=test_transform, download=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A train and test function for one epoch of data. We  use k nearest-neighbor (KNN) `knn_predict` to monitor the performance of the model. (see https://arxiv.org/abs/1805.01978 for more details).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for one epoch \n",
    "def train(train_loader, model, optimizer, device):\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "\n",
    "        if device is not None:\n",
    "            images[0] = images[0].to(device, non_blocking=True)\n",
    "            images[1] = images[1].to(device, non_blocking=True)\n",
    "\n",
    "        # compute output and loss\n",
    "        p1, p2, z1, z2 = model(x1=images[0], x2=images[1])\n",
    "        loss = model.loss(p1,p2,z1,z2,similarity_function='CosineSimilarity')\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return losses\n",
    "\n",
    "# save checkpoints \n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "# test using a knn monitor\n",
    "def test(net, memory_data_loader, test_data_loader, device, knn_k, knn_t ):\n",
    "    net.eval()\n",
    "    classes = len(memory_data_loader.dataset.classes)\n",
    "    total_top1, total_top5, total_num, feature_bank = 0.0, 0.0, 0, []\n",
    "    with torch.no_grad():\n",
    "        # generate feature bank\n",
    "        for i, (data, target) in enumerate(memory_data_loader):\n",
    "            feature = net(data.to(device,non_blocking=True))\n",
    "            feature = F.normalize(feature, dim=1)\n",
    "            feature_bank.append(feature)\n",
    "        # [D, N]\n",
    "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
    "        # [N]\n",
    "        feature_labels = torch.tensor(memory_data_loader.dataset.targets, device=feature_bank.device)\n",
    "        # loop test data to predict the label by weighted knn search\n",
    "        for i, (data, target) in enumerate(test_data_loader):\n",
    "            data, target = data.to(device,non_blocking=True), target.to(device,non_blocking=True)\n",
    "            feature = net(data)\n",
    "            feature = F.normalize(feature, dim=1)\n",
    "            \n",
    "            pred_labels = knn_predict(feature, feature_bank, feature_labels, classes, knn_k, knn_t)\n",
    "\n",
    "            total_num += data.size(0)\n",
    "            total_top1 += (pred_labels[:, 0] == target).float().sum().item()\n",
    "\n",
    "    return total_top1 / total_num * 100\n",
    "\n",
    "# knn monitor as in InstDisc https://arxiv.org/abs/1805.01978\n",
    "# implementation follows http://github.com/zhirongw/lemniscate.pytorch and https://github.com/leftthomas/SimCLR\n",
    "def knn_predict(feature, feature_bank, feature_labels, classes, knn_k, knn_t):\n",
    "    # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "    sim_matrix = torch.mm(feature, feature_bank)\n",
    "    # [B, K]\n",
    "    sim_weight, sim_indices = sim_matrix.topk(k=knn_k, dim=-1)\n",
    "    # [B, K]\n",
    "    sim_labels = torch.gather(feature_labels.expand(feature.size(0), -1), dim=-1, index=sim_indices)\n",
    "    sim_weight = (sim_weight / knn_t).exp()\n",
    "\n",
    "    # counts for each class\n",
    "    one_hot_label = torch.zeros(feature.size(0) * knn_k, classes, device=sim_labels.device)\n",
    "    # [B*K, C]\n",
    "    one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
    "    # weighted score ---> [B, C]\n",
    "    pred_scores = torch.sum(one_hot_label.view(feature.size(0), -1, classes) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
    "\n",
    "    pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "    return pred_labels\n",
    "\n",
    "# adjust LR\n",
    "def adjust_learning_rate(optimizer, init_lr, epoch, epochs):\n",
    "    \"\"\"Decay the learning rate based on schedule\"\"\"\n",
    "    cur_lr = init_lr * 0.5 * (1. + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if 'fix_lr' in param_group and param_group['fix_lr']:\n",
    "            param_group['lr'] = init_lr\n",
    "        else:\n",
    "            param_group['lr'] = cur_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model for X epochs: We can do the training with and without gradient stopping\n",
    "# To run the model without gradient-stopping you need to change `stop_gradient` to `False` and run the notebook.\n",
    "\n",
    "# train loop \n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # train for one epoch\n",
    "    losses = train(train_loader, model, optimizer, device)\n",
    "    print('Train Epoch: [{}/{}] Train Loss:{:.5f}'.format(epoch, epochs,np.array(losses).mean() ))\n",
    "\n",
    "\n",
    "    # test every 10 epochs\n",
    "    if epoch % 1==0:\n",
    "        acc1 = test(model.encoder, memory_loader, test_loader, device, knn_k, knn_t)\n",
    "        print('Test Epoch: [{}/{}] knn_Acc@1: {:.2f}%'.format(epoch, epochs, acc1))\n",
    "    \n",
    "    # save a checkpoint every 20 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best=False, filename=save_path + '/checkpoint_gradstop_{:04d}.pth.tar'.format(epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the pretraining the network, we can evalute the model in a classification task. In the next cells we will load the backbone model and train an supervised linear classifier on frozen features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear eval\n",
    "print(\"=> creating model '{}'\".format(arch))\n",
    "model = models.__dict__[arch]()\n",
    "\n",
    "# freeze all layers but the last fc\n",
    "for name, param in model.named_parameters():\n",
    "    if name not in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# init the fc layer\n",
    "model.fc.weight.data.normal_(mean=0.0, std=0.01)\n",
    "model.fc.bias.data.zero_()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained model from previous steps\n",
    "pretrained = './checkpoint_0001.pth.tar'\n",
    "if pretrained:\n",
    "    model, optimizer, start_epoch = load_pretrained_checkpoints(os.path.join(pretrained),model,optimizer,device)\n",
    "if device is not None:\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# optimize only the linear classifier\n",
    "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "assert len(parameters) == 2  # fc.weight, fc.bias\n",
    "\n",
    "optimizer = torch.optim.SGD(parameters, init_lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train and test augmentation for linear evaluation \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    dir,\n",
    "    transform=train_transform,\n",
    "    download=True,\n",
    "    train=True\n",
    "    )\n",
    "val_dataset = datasets.CIFAR10(\n",
    "    dir,\n",
    "    transform=val_transform,\n",
    "    download=True,\n",
    "    train=False\n",
    "    )\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, #(train_sampler is None),\n",
    "    num_workers=num_workers, pin_memory=True) #, sampler=train_sampler)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=256, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for one epoch\n",
    "def train(train_loader, model, criterion, optimizer, device):\n",
    "\n",
    "    \"\"\"\n",
    "    Switch to eval mode:\n",
    "    Under the protocol of linear classification on frozen features/models,\n",
    "    it is not legitimate to change any part of the pre-trained model.\n",
    "    BatchNorm in train mode may revise running mean/std (even if it receives\n",
    "    no gradient), which are part of the model parameters too.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses=[]\n",
    "    top1=[]\n",
    "    top5=[]\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "\n",
    "        if device is not None:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.append(loss.item())\n",
    "        top1.append(acc1[0].cpu())\n",
    "        top5.append(acc5[0].cpu())\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return top1\n",
    "\n",
    "# validation\n",
    "def validate(val_loader, model, criterion, device):\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    losses=[]\n",
    "    top1=[]\n",
    "    top5=[]\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if device is not None:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "            target = target.to(device, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.append(loss.item())\n",
    "            top1.append(acc1[0].cpu())\n",
    "            top5.append(acc5[0].cpu())\n",
    "\n",
    "    return top1\n",
    "\n",
    "\n",
    "def sanity_check(state_dict, pretrained_weights):\n",
    "    \"\"\"\n",
    "    Linear classifier should not change any weights other than the linear layer.\n",
    "    This sanity check asserts nothing wrong happens (e.g., BN stats updated).\n",
    "    \"\"\"\n",
    "    print(\"=> loading '{}' for sanity check\".format(pretrained_weights))\n",
    "    checkpoint = torch.load(pretrained_weights, map_location=\"cpu\")\n",
    "    state_dict_pre = checkpoint['state_dict']\n",
    "\n",
    "    for k in list(state_dict.keys()):\n",
    "        # only ignore fc layer\n",
    "        if 'fc.weight' in k or 'fc.bias' in k:\n",
    "            continue\n",
    "\n",
    "        # name in pretrained model\n",
    "        k_pre = 'encoder.' + k[len('module.'):] \\\n",
    "            if k.startswith('module.') else 'encoder.' + k\n",
    "\n",
    "        assert ((state_dict[k].cpu() == state_dict_pre[k_pre]).all()), \\\n",
    "            '{} is changed in linear classifier training.'.format(k)\n",
    "\n",
    "    print(\"=> sanity check passed.\")\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for the classififcation task\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    adjust_learning_rate(optimizer, init_lr, epoch, epochs)\n",
    "\n",
    "    # train for one epoch\n",
    "    acc1 = train(train_loader, model, criterion, optimizer,device)\n",
    "    print('Train Epoch: [{}/{}] Train acc1:{:.2f}%'.format(epoch, epochs,np.array(acc1).mean() ))\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion, device)\n",
    "    print('Val Epoch: [{}/{}] Val acc1:{:.2f}%'.format(epoch, epochs,np.array(acc1).mean() ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can experiment also with replacing the predictor with an identity network in the first cell (change MLP mode). And with uncreasing the dimensionality of the last layer of the projector network (from 2048 to 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 64-bit ('3.8.16')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c925766edaeb2e096b5ab9d3f363c193adbad705f69f6eaee42a6c9eedbbfe3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
